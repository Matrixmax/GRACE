package core

import (
	"fmt"
	"go/ast"
	"go/scanner"
	"go/token"
	"go/types"
	"io/ioutil"
	"log"
	"os"
	"path/filepath"
	"regexp"
	"strconv"
	"strings"

	"alipay.com/code_insight/coref-go-extractor/src/orm"
	"alipay.com/code_insight/coref-go-extractor/src/util"
	"golang.org/x/tools/go/packages"
)

// Create a map to keep track of processed paths to avoid duplicates.
var processedPaths = make(map[string]struct{})

// pathIgnoreRegex is a regular expression that matches paths that should be ignored.
// The pathIgnoreRegex regular expression is defined to match any string that contains any of the following substrings:
//
//	"vendor"
//	".test"
//	"autogenerated"
//	".."
//
// Note: The regular expression also includes a placeholder for the file separator character,
// which is escaped and quoted using the regexp.QuoteMeta function.
// This ensures that the regular expression will work on any operating system, regardless of the file separator character used.
var pathIgnoreRegex = regexp.MustCompile(`.*(^|` + regexp.QuoteMeta(string(filepath.Separator)) + `)(vendor|\.test|autogenerated|\.\.)`)

// isIgnorePath returns true if the given package's path matches the pathIgnoreRegex regular expression.
// Otherwise, it returns false.
func isIgnorePath(path string) bool {
	// Check if the path matches the pathIgnoreRegex regular expression.
	if pathIgnoreRegex.MatchString(path) {
		return true
	}
	return false
}

// autoGeneratedSignRegex is a regular expression that matches common phrases
// used in automatically generated code.
// determine whether a Go file was automatically generated:
// specific phrases that are commonly used in automatically generated code:
//
//	"automatically generated",
//	"do not edit",
//	"generated by".
var autoGeneratedSignRegex = regexp.MustCompile(`(?i)(automatically generated|do not edit|generated by|do not modify)`)

func isAutoGenerated(file *ast.File) bool {
	// Check the comments in the file for any indicators of automatic generation.
	for _, cg := range file.Comments {
		for _, c := range cg.List {
			if autoGeneratedSignRegex.MatchString(c.Text) {
				return true
			}
		}
	}
	// Return false if no indication of automatic generation was found.
	return false
}

// extractPackage extract a package
func (ex *Extraction) extractPackage(pkg *packages.Package) {
	// Compile the regular expression only once, before the loop.
	sep := regexp.QuoteMeta(string(filepath.Separator))
	extractRe := regexp.MustCompile(fmt.Sprintf(`.*(^|%s)(%s)($|%s).*`, sep, regexp.QuoteMeta(ex.SrcRootDir), sep))

	for _, astFile := range pkg.Syntax {
		path := normalizedPath(astFile, pkg.Fset)

		// Skip files that do not match the extract regexp.
		if !extractRe.MatchString(path) {
			continue
		}

		// Record autogenerated files as unextracted.
		if isAutoGenerated(astFile) {
			ex.recordAutoGeneratedFile(path)
			continue
		}

		// Avoid re-extracting a file that has already been processed.
		if _, exists := processedPaths[path]; exists {
			continue
		}
		processedPaths[path] = struct{}{}

		// Extract the file contents using a goroutine.
		ex.WaitGroup.Add(1)
		go func(astFile *ast.File) {
			defer ex.WaitGroup.Done()
			if err := ex.extractFile(astFile, pkg); err != nil {
				util.PrintTracebackAfterDetectedBadEntrance(1, err)
			}
		}(astFile)
	}
}

// recordAutoGeneratedFile handles storing auto-generated files in the unextracted table.
func (ex *Extraction) recordAutoGeneratedFile(path string) {
	ex.StatProfile.StoreTable(&orm.UnExtracted{
		Oid:  ex.StatProfile.Labeler.FileLabelFor(path).ID,
		Type: orm.TypeFile,
		Name: localizedPath(path, ex.SrcRootDir),
	})
}

// extractScopes extracts symbol table information for the package scope and all local scopes
// of the given package
func extractScopes(p *Profile, nd *ast.File, pkg *packages.Package) {
	pkgScopeLabel := extractPackageScope(p, pkg)
	fileScope := pkg.TypesInfo.Scopes[nd]
	if fileScope != nil {
		extractLocalScope(p, fileScope, pkgScopeLabel)
	}
}

// extractPackageScope extracts symbol table information for the given package
func extractPackageScope(p *Profile, pkg *packages.Package) Label {
	pkgScope := pkg.Types.Scope()
	pkgScopeLabel := Label{util.GetIDFromDigest(fmt.Sprintf("{%s}", util.EscapeTrapSpecialChars(pkg.Types.Path())), "PackageScope")} //p.Labeler.ScopeID(pkgScope, pkg.Types)
	p.StoreTable(&orm.Scope{
		Oid:       pkgScopeLabel.ID,
		Kind:      orm.PackageScopeType.Index(),
		DebugInfo: orm.PackageScopeType.String(),
	})
	p.StoreTable(&orm.ScopeNesting{
		Oid:   util.GetIDFromDigest(fmt.Sprintf("%v#%v", p.Path, pkgScopeLabel.ID), "ScopeNesting"),
		Inner: pkgScopeLabel.ID,
		Outer: p.Labeler.ScopeID(types.Universe, nil).ID,
	})

	extractObjects(p, pkgScope, pkgScopeLabel)
	return pkgScopeLabel
}

// extractObjects extracts all objects declared in the given scope
func extractObjects(p *Profile, scope *types.Scope, scopeLabel Label) {
	for _, name := range scope.Names() {
		obj := scope.Lookup(name)
		lbl, exists := p.Labeler.ScopedObjectID(obj, func() Label { lb, _ := extractType(p, obj.Type()); return lb })
		if !exists {
			// Populate type parameter parents for functions. Note that methods
			// do not appear as objects in any scope, so they have to be dealt
			// with separately in extractMethods.
			if funcObj, ok := obj.(*types.Func); ok {
				populateTypeParamParents(p, funcObj.Type().(*types.Signature).TypeParams(), obj)
				populateTypeParamParents(p, funcObj.Type().(*types.Signature).RecvTypeParams(), obj)
			}
			// Populate type parameter parents for named types. Note that we
			// skip type aliases as the original type should be the parent
			// of any type parameters.
			if typeNameObj, ok := obj.(*types.TypeName); ok && !typeNameObj.IsAlias() {
				if tp, ok := typeNameObj.Type().(*types.Named); ok {
					populateTypeParamParents(p, tp.TypeParams(), obj)
				}
			}

			extractObject(p, obj, lbl)
		}

		if obj.Parent() != scope {
			// this can happen if a scope is embedded into another with a `.` import.
			continue
		}
		p.StoreTable(&orm.ObjectScope{
			Oid:    util.GetIDFromDigest(fmt.Sprintf("%v#%v", p.Path, lbl.ID), "ObjectScope"),
			Object: lbl.ID,
			Scope:  scopeLabel.ID,
		})
	}
}

// extractScopeLocation extracts location information for the given scope
func extractScopeLocation(p *Profile, scope *types.Scope, lbl Label) {
	fset := p.Package.Fset
	start, end, startOffset, endOffset := fset.Position(scope.Pos()), fset.Position(scope.End()), fset.Position(scope.Pos()).Offset, fset.Position(scope.End()).Offset
	extractLocation(p, lbl, start.Line, start.Column, end.Line, end.Column-1, startOffset, endOffset)
}

// emitObjectType emits the type information for a given object
func emitObjectType(p *Profile, obj types.Object, lbl Label) {
	if tp := obj.Type(); tp != nil {
		p.StoreTable(&orm.ObjectType{
			Object: lbl.ID,
			Tp:     func(p *Profile, tp types.Type) int64 { lb, _ := extractType(p, tp); return lb.ID }(p, tp),
		})
	}
}

// extractError extracts information about a compilation error and stores it
// in the database using ORM. It parses the error position, extracts file system
// information, and stores error details in ORM table entries.
func (ex *Extraction) extractError(p *Profile, err packages.Error, pkglbl Label, idx int) {
	lbl := p.Labeler.FreshID()
	tag := orm.ErrorTags[err.Kind]
	kind := orm.ErrorTypes[err.Kind].Index()
	pos := err.Pos
	file, line, col := parseErrorPosition(pos)

	if file != "" {
		// Extract file information if the file path is non-empty.
		ex.extractFileInfo(p, file)
		ex.Lock()
		flbl := ex.StatProfile.Labeler.FileLabelFor(file)
		ex.Unlock()

		emitErrorDiagnostic(ex, p, flbl, err, tag, file, line, col)
	}

	file = filepath.ToSlash(file) // Normalize file path to use forward slashes.
	storeError(p, lbl, kind, err, pos, file, line, col, pkglbl, idx)
}

// parseErrorPosition parses the error position string to extract the file path,
// line number, and column number. It returns a normalized file path and the
// extracted line and column numbers. If the position is empty or "-", a dummy
// error file is created.
func parseErrorPosition(pos string) (file string, line int, col int) {
	var e error

	if pos == "" || pos == "-" {
		file, e = createDummyErrorFile()
		if e != nil {
			log.Printf("Warning: failed to create dummy error file: %v", e)
		}
		return
	}

	file, line, col = extractPositionComponents(pos)
	file, e = getEvaluatedPath(file)
	if e != nil {
		log.Printf("Warning: failed to evaluate path for %s: %v", file, e)
	}

	return
}

// createDummyErrorFile creates a dummy file path for errors that lack specific
// position information. It constructs the path based on the current working
// directory and returns it.
func createDummyErrorFile() (string, error) {
	wd, err := os.Getwd()
	if err != nil {
		log.Printf("Warning: failed to get working directory: %v", err)
		return ".", nil
	}
	ewd, err := filepath.EvalSymlinks(wd)
	if err != nil {
		log.Printf("Warning: failed to evaluate symlinks for %s: %v", wd, err)
		return wd, nil
	}
	return filepath.Join(ewd, "-"), nil
}

// extractPositionComponents parses the error position string and extracts the
// file path, line number, and column number from it. It returns these components
// for further processing.
func extractPositionComponents(pos string) (file string, line int, col int) {
	var (
		// file:line:col
		threePartPos = regexp.MustCompile(`^(.+):(\d+):(\d+)$`)
		// file:line
		twoPartPos = regexp.MustCompile(`^(.+):(\d+)$`)
	)

	if parts := threePartPos.FindStringSubmatch(pos); parts != nil {
		// "file:line:col"
		col = parseNumber(parts[3], "column")
		line = parseNumber(parts[2], "line")
		file = parts[1]
	} else if parts := twoPartPos.FindStringSubmatch(pos); parts != nil {
		// "file:line"
		line = parseNumber(parts[2], "line")
		file = parts[1]
	} else {
		log.Printf("Warning: malformed error position `%s`", pos)
	}
	return
}

// parseNumber parses a string representing a number and converts it to an integer.
// It is used to parse line and column numbers from the error position string.
// If parsing fails, it logs a warning and returns zero.
func parseNumber(numStr, label string) int {
	num, err := strconv.Atoi(numStr)
	if err != nil {
		log.Printf("Warning: malformed %s number `%s`: %v", label, numStr, err)
	}
	return num
}

// getEvaluatedPath evaluates and returns the absolute path for a given file path,
// resolving any symbolic links.
func getEvaluatedPath(rawfile string) (string, error) {
	afile, err := filepath.Abs(rawfile)
	if err != nil {
		return "", err
	}
	return filepath.EvalSymlinks(afile)
}

// emitErrorDiagnostic emits diagnostic information associated with an error.
func emitErrorDiagnostic(ex *Extraction, p *Profile, fileLabel Label, err packages.Error, tag, file string, line, col int) {
	diagLbl := ex.StatProfile.Labeler.FreshID()
	p.StoreTable(&orm.Diagnostic{
		Oid:              diagLbl.ID,
		Severity:         1,
		ErrorTag:         tag,
		ErrorMessage:     err.Msg,
		FullErrorMessage: err.Msg,
		LocationId:       emitLocation(ex.StatProfile, fileLabel, line, col, line, col, line, col).ID,
	})
	p.StoreTable(&orm.DiagnosticFor{
		Diagnostic:                 diagLbl.ID,
		Compilation:                ex.Label.ID,
		FileNumber:                 ex.GetFileIdx(file),
		FileNumberDiagnosticNumber: ex.GetNextErr(file),
	})
}

// storeError stores information about an error in the ORM database.
func storeError(p *Profile, label Label, kind int, err packages.Error, pos, file string, line, col int, pkgLabel Label, idx int) {
	transformed := filepath.ToSlash(file)
	p.StoreTable(&orm.Error{
		Oid:    label.ID,
		Kind:   kind,
		Msg:    err.Msg,
		RawPos: pos,
		File:   transformed,
		Line:   line,
		Col:    col,
		Pkg:    pkgLabel.ID,
		Idx:    idx,
	})
}

func localizedPath(absPath, prefix string) string {
	if !strings.HasPrefix(absPath, prefix) {
		log.Println("[Warning]getFileRelativePath: can't find path prefix")
		return absPath
	}
	rpath := absPath[len(prefix):]
	rpath = strings.TrimPrefix(rpath, "/")
	return rpath
}

// extractFileInfo extracts file-system level information for the given file
func (ex *Extraction) extractFileInfo(p *Profile, file string) {
	ex.Lock()
	if ex.SeenFile(file) {
		ex.Unlock()
		return
	}
	ex.MarkFileAsSeen(file)
	ex.Unlock()

	md5Sum, err := util.GetFileDigest(file, "md5")
	if err != nil {
		log.Fatalf("Error getting MD5 digest for file %s: %v", file, err)
	}
	sha256Sum, err := util.GetFileDigest(file, "sha256")
	if err != nil {
		log.Fatalf("Error getting SHA256 digest for file %s: %v", file, err)
	}

	path := filepath.ToSlash(util.GetFileFullPath(file))
	components := strings.Split(path, "/")
	parentPath := ""
	var parentLbl Label

	// Use a separate function to avoid repeated file reads for the content.
	fileContent := readFileContent(file)

	for i, component := range components {
		currentPath := getPath(component, i, parentPath)
		isLastComponent := i == len(components)-1

		// Handle the last component, which is the file itself.
		if isLastComponent {
			handleFile(p, ex, file, md5Sum, sha256Sum, currentPath, parentLbl, fileContent)
			break
		}

		// For intermediate components, create labels for folders.
		lbl := p.Labeler.GlobalID(util.EscapeTrapSpecialChars(currentPath) + ";folder")
		storeFolder(p, lbl, currentPath, parentLbl, i)

		if currentPath != "/" {
			parentPath = currentPath
		}
		parentLbl = lbl
	}
}

// Read the file content once and return it as a string.
func readFileContent(file string) string {
	data, err := util.ReadFile(file)
	if err != nil {
		util.PrintTracebackAfterDetectedBadEntrance(1, err)
		return ""
	}
	return string(data)
}

// Construct the path for the current component.
func getPath(component string, index int, parentPath string) string {
	if index == 0 {
		if component == "" {
			return "/"
		}
		return component
	}
	return parentPath + "/" + component
}

// Handle the storage of file-related ORM items.
func handleFile(p *Profile, ex *Extraction, file, md5Sum, sha256Sum, path string, parentLbl Label, content string) {
	lbl := p.Labeler.FileLabelFor(file)
	localPath := localizedPath(path, ex.SrcRootDir)
	storeFile(p, lbl, localPath, md5Sum, sha256Sum, content, parentLbl)
	storeCompilationCompilingFile(ex, p, file)
}

// Store the file and related ORM items.
func storeFile(p *Profile, lbl Label, localPath, md5Sum, sha256Sum, content string, parentLbl Label) {
	p.StoreTable(&orm.File{
		Oid:       lbl.ID,
		PkgOid:    getPkgLableID(p.Package).ID,
		Name:      localPath,
		Md5Sum:    md5Sum,
		Sha256Sum: sha256Sum,
	})
	p.StoreTable(&orm.FileData{
		Oid:     util.GetIDFromDigest(fmt.Sprintf("%v#%v", p.Path, lbl.ID), "FileData"),
		FileId:  lbl.ID,
		Type:    orm.GoFile,
		Content: content,
	})
	p.StoreTable(&orm.ContainerParent{
		Oid:    util.GetIDFromDigest(fmt.Sprintf("%v#%v", p.Path, lbl.ID), "ContainerParent"),
		Parent: parentLbl.ID,
		Child:  lbl.ID,
	})
	p.StoreTable(&orm.HasLocation{
		Oid:         util.GetIDFromDigest(fmt.Sprintf("%v#%v", p.Path, lbl.ID), "HasLocation"),
		LocationObj: lbl.ID,
		LocationId:  emitLocation(p, lbl, 0, 0, 0, 0, 0, 0).ID,
	})
}

// Store the ORM item for the compilation compiling file.
func storeCompilationCompilingFile(ex *Extraction, p *Profile, file string) {
	ex.Lock()
	slbl := ex.StatProfile.Labeler.FileLabelFor(file)
	p.StoreTable(&orm.CompilationCompilingFile{
		Oid:  ex.Label.ID,
		Num:  ex.GetFileIdx(file),
		File: slbl.ID,
	})
	ex.Unlock()
}

// Store folder ORM items for intermediate components.
func storeFolder(p *Profile, lbl Label, path string, parentLbl Label, idx int) {
	p.StoreTable(&orm.Folder{
		Oid:  lbl.ID,
		Name: path,
	})
	if idx > 0 {
		p.StoreTable(&orm.ContainerParent{
			Oid:    util.GetIDFromDigest(fmt.Sprintf("%v#%v", p.Path, lbl.ID), "ContainerParent"),
			Parent: parentLbl.ID,
			Child:  lbl.ID,
		})
	}
}

// extractNumLines extracts the number of total, code, and comment lines in a file.
func extractNumLines(p *Profile, fileName string, ast *ast.File) error {
	f := p.Package.Fset.File(ast.Pos())
	lineCount := f.LineCount()

	// Count lines of code by tokenizing.
	linesOfCode, err := countLinesOfCode(f, fileName)
	if err != nil {
		return fmt.Errorf("error counting lines of code for %s: %w", fileName, err)
	}

	// Count lines of comments by iterating over ast.Comments.
	linesOfComments := countLinesOfComments(p.Package.Fset, ast.Comments)

	// Store the number of lines information.
	p.StoreTable(&orm.NumberOfLine{
		Oid:                  p.Labeler.GetFileLabel().ID,
		NumberOfTotalLines:   lineCount,
		NumberOfCodeLines:    linesOfCode,
		NumberOfCommentLines: linesOfComments,
	})

	return nil
}

// countLinesOfCode counts the number of code lines in a file by tokenizing its content.
func countLinesOfCode(fset *token.File, fileName string) (int, error) {
	src, err := ioutil.ReadFile(fileName)
	if err != nil {
		return 0, err
	}

	var s scanner.Scanner
	linesOfCode := 0
	lastCodeLine := -1

	s.Init(fset, src, nil, 0)
	for {
		pos, tok, lit := s.Scan()
		if tok == token.EOF {
			break
		} else if tok != token.ILLEGAL && !(tok == token.SEMICOLON && lit == "\n") {
			posLine := fset.Position(pos).Line
			if posLine > lastCodeLine {
				linesOfCode++
				lastCodeLine = posLine
			}
			if strings.Contains(lit, "\n") {
				// Token contains newlines, indicating multiple lines.
				linesInToken := strings.Count(lit, "\n")
				linesOfCode += linesInToken
				lastCodeLine += linesInToken
			}
		}
	}

	return linesOfCode, nil
}

// countLinesOfComments counts the number of comment lines by iterating over comment groups.
func countLinesOfComments(fset *token.FileSet, comments []*ast.CommentGroup) int {
	linesOfComments := 0
	for _, cg := range comments {
		for _, c := range cg.List {
			startLine := fset.Position(c.Pos()).Line
			endLine := fset.Position(c.End()).Line
			linesOfComments += endLine - startLine + 1
		}
	}
	return linesOfComments
}

// normalizedPath computes the normalized path (with symlinks resolved) for the given file
func normalizedPath(ast *ast.File, fset *token.FileSet) string {
	if !ast.Package.IsValid() {
		util.PrintTracebackAfterDetectedBadEntrance(1, fmt.Errorf("ast.Package is invalid"), false)
		return ""
	}

	file := fset.File(ast.Package).Name()
	path, err := filepath.EvalSymlinks(file)
	if err != nil {
		return file
	}
	return path
}

// extractUniverseScope extracts symbol table information for the universe scope
func (ex *Extraction) extractUniverseScope() {
	p, err := NewProfile("universe", nil, ex.Db, &ex.IDManager, ex.SrcRootDir)
	if err != nil {
		util.PrintTracebackAfterDetectedBadEntrance(1, err)
	}

	lbl := Label{util.GetIDFromDigest("universe;scope", "Scope")} // p.Labeler.ScopeID(types.Universe, nil)
	p.StoreTable(&orm.Scope{
		Oid:       lbl.ID,
		Kind:      orm.UniverseScopeType.Index(),
		DebugInfo: orm.UniverseScopeType.String(),
	})
	extractObjects(p, types.Universe, lbl)

	// Always extract an empty interface type
	extractType(p, types.NewInterfaceType([]*types.Func{}, []types.Type{}))
}

// extractObjectTypes extracts type and receiver information for all objects
func extractObjectTypes(p *Profile) {
	// calling `extractType` on a named type will extract all methods defined
	// on it, which will add new objects. Therefore, we need to do this first
	// before we loops over all objects and emit them.
	changed := true
	for changed {
		changed = p.ForEachObject(extractObjectType)
	}
	changed = p.ForEachObject(emitObjectType)
	if changed {
		log.Printf("Warning: more objects were labeled while emitted object types")
	}
}

// extractObjectType extracts type and receiver information for a given object
func extractObjectType(p *Profile, obj types.Object, lbl Label) {
	if tp := obj.Type(); tp != nil {
		extractType(p, tp)
	}
}
